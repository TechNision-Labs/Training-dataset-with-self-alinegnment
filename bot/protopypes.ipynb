{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import jsonlines\n",
    "from langchain.schema import Document\n",
    "def load_config():\n",
    "    \"\"\"\n",
    "    Carga la configuración de la aplicación desde el archivo 'config.yaml'.\n",
    "\n",
    "    Returns:\n",
    "        Un diccionario con la configuración de la aplicación.\n",
    "    \"\"\"\n",
    "    root_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    with open(os.path.join(root_dir, \"config.yaml\")) as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "def get_file_path():\n",
    "    \"\"\"\n",
    "    Obtiene la ruta al archivo de base de datos JSONL especificado en la configuración de la aplicación.\n",
    "\n",
    "    Returns:\n",
    "        La ruta al archivo de base de datos JSONL.\n",
    "    \"\"\"\n",
    "    config = load_config()\n",
    "\n",
    "    root_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    parent_dir = os.path.join(root_dir, \"..\")\n",
    "\n",
    "    return os.path.join(parent_dir, config[\"jsonl_database_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "get_openai_api_key()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  model_name=\"gpt-3.5-turbo\",\n",
    "  temperature=0.2,\n",
    "  max_tokens=1000,  # Queremos que las respuestas sean tan largas como el modelo lo considere, sin considerar la cantidad de tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import json\n",
    "\n",
    "path = \"../data/gse_2023_11_09.jsonl\"\n",
    "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "len_token = []\n",
    "tex_list = []\n",
    "pages = []\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        text = data['text']\n",
    "        pages.append(data['page'])\n",
    "        len_token.append(num_tokens_from_string(text))\n",
    "        tex_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pag</th>\n",
       "      <th>Num_tokens</th>\n",
       "      <th>Texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>Aprobada por Resolución de Presidencia de Cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>Guía para el seguimiento y evaluación de polít...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>CENTRO NACIONAL DE PLANEAMIENTO ESTRATÉGICO - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>4 GUÍA PARA EL SEGUIMIENTO Y EVALUACIÓN DE POL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>CENTRO NACIONAL DE PLANEAMIENTO ESTRATÉGICO - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>152</td>\n",
       "      <td>434</td>\n",
       "      <td>152 GUÍA PARA EL SEGUIMIENTO Y EVALUACIÓN DE P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>153</td>\n",
       "      <td>876</td>\n",
       "      <td>CENTRO NACIONAL DE PLANEAMIENTO ESTRATÉGICO - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>154</td>\n",
       "      <td>867</td>\n",
       "      <td>154 GUÍA PARA EL SEGUIMIENTO Y EVALUACIÓN DE P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>155</td>\n",
       "      <td>793</td>\n",
       "      <td>CENTRO NACIONAL DE PLANEAMIENTO ESTRATÉGICO - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>87</td>\n",
       "      <td>156 GUÍA PARA EL SEGUIMIENTO Y EVALUACIÓN DE P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pag  Num_tokens                                              Texto\n",
       "0      1          57  Aprobada por Resolución de Presidencia de Cons...\n",
       "1      2         231  Guía para el seguimiento y evaluación de polít...\n",
       "2      3          76  CENTRO NACIONAL DE PLANEAMIENTO ESTRATÉGICO - ...\n",
       "3      4          32  4 GUÍA PARA EL SEGUIMIENTO Y EVALUACIÓN DE POL...\n",
       "4      5          22  CENTRO NACIONAL DE PLANEAMIENTO ESTRATÉGICO - ...\n",
       "..   ...         ...                                                ...\n",
       "151  152         434  152 GUÍA PARA EL SEGUIMIENTO Y EVALUACIÓN DE P...\n",
       "152  153         876  CENTRO NACIONAL DE PLANEAMIENTO ESTRATÉGICO - ...\n",
       "153  154         867  154 GUÍA PARA EL SEGUIMIENTO Y EVALUACIÓN DE P...\n",
       "154  155         793  CENTRO NACIONAL DE PLANEAMIENTO ESTRATÉGICO - ...\n",
       "155  156          87  156 GUÍA PARA EL SEGUIMIENTO Y EVALUACIÓN DE P...\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"pag\":pages,\"Num_tokens\":len_token, \"Texto\":tex_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1323"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df.Num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'proposition_1, proposition_2,'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3. TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m template_string \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mYou are tasked with extracting a logic proposition fron the given text, remember to be caution \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mand consider the proposition should be related to government planning. Consider based in informative entities, where \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39minformative entities are: relevant to the main topic, faithful and should present in the given Text, and located \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mGiven text: \u001b[39m\u001b[39m{text}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m prompt_template \u001b[39m=\u001b[39m ChatPromptTemplate\u001b[39m.\u001b[39mfrom_template(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                     template_string\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                   )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m message \u001b[39m=\u001b[39m prompt_template\u001b[39m.\u001b[39;49mformat_messages(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m   text \u001b[39m=\u001b[39;49m df[\u001b[39m\"\u001b[39;49m\u001b[39mTexto\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m   )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m response \u001b[39m=\u001b[39m chat(message)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3.%20TechNision/Training-dataset-with-self-alinegnment/bot/draf.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/site-packages/langchain/prompts/chat.py:588\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    581\u001b[0m     message_template, (BaseMessagePromptTemplate, BaseChatPromptTemplate)\n\u001b[1;32m    582\u001b[0m ):\n\u001b[1;32m    583\u001b[0m     rel_params \u001b[39m=\u001b[39m {\n\u001b[1;32m    584\u001b[0m         k: v\n\u001b[1;32m    585\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    586\u001b[0m         \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m message_template\u001b[39m.\u001b[39minput_variables\n\u001b[1;32m    587\u001b[0m     }\n\u001b[0;32m--> 588\u001b[0m     message \u001b[39m=\u001b[39m message_template\u001b[39m.\u001b[39;49mformat_messages(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrel_params)\n\u001b[1;32m    589\u001b[0m     result\u001b[39m.\u001b[39mextend(message)\n\u001b[1;32m    590\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/site-packages/langchain/prompts/chat.py:195\u001b[0m, in \u001b[0;36mBaseStringMessagePromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_messages\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseMessage]:\n\u001b[1;32m    187\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format messages from kwargs.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m        List of BaseMessages.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)]\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/site-packages/langchain/prompts/chat.py:241\u001b[0m, in \u001b[0;36mHumanMessagePromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m    233\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format the prompt template.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[1;32m    235\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39m        Formatted message.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt\u001b[39m.\u001b[39;49mformat(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    242\u001b[0m     \u001b[39mreturn\u001b[39;00m HumanMessage(content\u001b[39m=\u001b[39mtext, additional_kwargs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madditional_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/site-packages/langchain/prompts/prompt.py:126\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m        prompt.format(variable1=\"foo\")\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_partial_and_user_variables(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m DEFAULT_FORMATTER_MAPPING[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemplate_format](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemplate, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/string.py:161\u001b[0m, in \u001b[0;36mFormatter.format\u001b[0;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, format_string, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvformat(format_string, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/site-packages/langchain/utils/formatting.py:29\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo arguments should be provided, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39meverything should be passed as keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[0;32m---> 29\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvformat(format_string, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/string.py:165\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvformat\u001b[39m(\u001b[39mself\u001b[39m, format_string, args, kwargs):\n\u001b[1;32m    164\u001b[0m     used_args \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m--> 165\u001b[0m     result, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vformat(format_string, args, kwargs, used_args, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[1;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/string.py:205\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[0;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[1;32m    201\u001b[0m     auto_arg_index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m# given the field_name, find the object it references\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m#  and the argument it came from\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m obj, arg_used \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_field(field_name, args, kwargs)\n\u001b[1;32m    206\u001b[0m used_args\u001b[39m.\u001b[39madd(arg_used)\n\u001b[1;32m    208\u001b[0m \u001b[39m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/string.py:270\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[0;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_field\u001b[39m(\u001b[39mself\u001b[39m, field_name, args, kwargs):\n\u001b[1;32m    268\u001b[0m     first, rest \u001b[39m=\u001b[39m _string\u001b[39m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[0;32m--> 270\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_value(first, args, kwargs)\n\u001b[1;32m    272\u001b[0m     \u001b[39m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[39m#  getattr or getitem as needed\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[39mfor\u001b[39;00m is_attr, i \u001b[39min\u001b[39;00m rest:\n",
      "File \u001b[0;32m~/miniconda3/envs/training-dataset/lib/python3.10/string.py:227\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[0;34m(self, key, args, kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mreturn\u001b[39;00m args[key]\n\u001b[1;32m    226\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mreturn\u001b[39;00m kwargs[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'proposition_1, proposition_2,'"
     ]
    }
   ],
   "source": [
    "# Modelo de chat\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from utils import get_openai_api_key\n",
    "\n",
    "get_openai_api_key()\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "\n",
    "# Prompt template\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template_string = \"\"\"You are tasked with extracting a logic proposition fron the given text, remember to be caution \\\n",
    "and consider the proposition should be related to government planning. Consider based in informative entities, where \\\n",
    "informative entities are: relevant to the main topic, faithful and should present in the given Text, and located \\\n",
    "anywhere in the text. Provide the proposition in this format: [proposition_1, proposition_2,...]\n",
    "\n",
    "Given text: {text}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "                    template_string\n",
    "                  )\n",
    "\n",
    "message = prompt_template.format_messages(\n",
    "  text = df[\"Texto\"][0]\n",
    "  )\n",
    "\n",
    "response = chat(message)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proposition(Texto):\n",
    "  message = prompt_template.format_messages(\n",
    "    text = Texto\n",
    "    )\n",
    "  return(message.content)\n",
    "\n",
    "df = df.assign(\n",
    "  proposition = df.apply(lambda x: get_proposition(x.Texto), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analitica_survey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
